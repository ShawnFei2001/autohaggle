{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/"
      ],
      "metadata": {
        "id": "iu9KE0dgTB2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install catboost --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GindxNT2jwt",
        "outputId": "333837fd-2f91-4a87-b174-9ea8658b4d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.cluster import KMeans\n",
        "import os\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/merged_data_2024_column.csv\")\n",
        "df.drop(columns=[\"sellingprice\", \"zipcode\", \"sale_year\"], inplace=True)\n",
        "\n",
        "# Define columns\n",
        "categorical_cols = ['make', 'model', 'trim', 'state', 'color', 'interior']\n",
        "numerical_cols = ['year', 'condition', 'odometer', 'mmr']\n",
        "cluster_features = ['year', 'condition', 'odometer', 'mmr']\n",
        "\n",
        "# Clustering\n",
        "scaler_for_clustering = StandardScaler()\n",
        "scaled_features = scaler_for_clustering.fit_transform(df[cluster_features])\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "df[\"cluster\"] = kmeans.fit_predict(scaled_features)\n",
        "print(\"CLUSTER 0: \", len(df[df[\"cluster\"] == 0]))\n",
        "print(\"CLUSTER 1: \", len(df[df[\"cluster\"] == 1]))\n",
        "print(\"CLUSTER 2: \", len(df[df[\"cluster\"] == 2]))\n",
        "\n",
        "joblib.dump(kmeans, \"kmeans_model.joblib\")\n",
        "joblib.dump(scaler_for_clustering, \"scaler_for_clustering.joblib\")\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_data(df, categorical_cols, numerical_cols, label_encoders=None, scaler=None, fit=True):\n",
        "    df = df.copy()\n",
        "    if fit:\n",
        "        label_encoders = {col: LabelEncoder().fit(df[col].astype(str)) for col in categorical_cols}\n",
        "        scaler = StandardScaler().fit(df[numerical_cols])\n",
        "    for col in categorical_cols:\n",
        "        df[col] = label_encoders[col].transform(df[col].astype(str))\n",
        "    df[numerical_cols] = scaler.transform(df[numerical_cols])\n",
        "    return df, label_encoders, scaler\n",
        "\n",
        "# Create directory\n",
        "os.makedirs(\"models_by_cluster\", exist_ok=True)\n",
        "\n",
        "# Train and save LightGBM models per cluster\n",
        "for cluster in [0, 1, 2]:\n",
        "    df_cluster = df[df['cluster'] == cluster].copy()\n",
        "    X = df_cluster.drop(columns=['2024_price', 'cluster'])\n",
        "    y = np.log1p(df_cluster['2024_price'])\n",
        "\n",
        "    X_encoded, label_encoders, scaler = preprocess_data(X, categorical_cols, numerical_cols, fit=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    joblib.dump(label_encoders, f\"models_by_cluster/label_encoders_cluster_{cluster}.joblib\", compress=3)\n",
        "    joblib.dump(scaler, f\"models_by_cluster/scaler_cluster_{cluster}.joblib\", compress=3)\n",
        "\n",
        "    # Different hyperparameters for cluster 1\n",
        "    model = lgb.LGBMRegressor(\n",
        "        num_leaves=80 if cluster == 1 else 50,\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.3 if cluster == 1 else 0.5,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    joblib.dump({'model': model}, f\"models_by_cluster/lightgbm_model_cluster_{cluster}.joblib\", compress=3)\n",
        "\n",
        "# ---- Prediction Function ---- #\n",
        "\n",
        "def predict_cluster_and_price(car_input: pd.DataFrame):\n",
        "    cluster_input = car_input[cluster_features].copy()\n",
        "    cluster_scaled = scaler_for_clustering.transform(cluster_input)\n",
        "    cluster = kmeans.predict(cluster_scaled)[0]\n",
        "\n",
        "    label_encoders = joblib.load(f\"models_by_cluster/label_encoders_cluster_{cluster}.joblib\")\n",
        "    scaler = joblib.load(f\"models_by_cluster/scaler_cluster_{cluster}.joblib\")\n",
        "\n",
        "    car = car_input.copy()\n",
        "    for col in categorical_cols:\n",
        "        car[col] = label_encoders[col].transform(car[col].astype(str))\n",
        "    X_cat = car[categorical_cols].values\n",
        "    X_num = scaler.transform(car[numerical_cols])\n",
        "    X_input = np.hstack((X_cat, X_num)).astype(np.float32)\n",
        "\n",
        "    model = joblib.load(f\"models_by_cluster/lightgbm_model_cluster_{cluster}.joblib\")['model']\n",
        "    y_log_pred = model.predict(X_input)\n",
        "    y_pred = np.expm1(y_log_pred)\n",
        "    return cluster, y_pred[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DtxK_7qxo7f",
        "outputId": "74dec26e-8194-4886-961c-5338d3c724a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-c1fc294cc2b4>:12: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/merged_data_2024_column.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLUSTER 0:  136622\n",
            "CLUSTER 1:  461080\n",
            "CLUSTER 2:  71190\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011512 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1154\n",
            "[LightGBM] [Info] Number of data points in the train set: 109297, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 10.370771\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038363 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1391\n",
            "[LightGBM] [Info] Number of data points in the train set: 368864, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 9.128428\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1190\n",
            "[LightGBM] [Info] Number of data points in the train set: 56952, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 9.256129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.cluster import KMeans\n",
        "import os\n",
        "\n",
        "# === CONFIG === #\n",
        "categorical_cols = ['make', 'model', 'trim', 'state', 'color', 'interior']\n",
        "original_numerical = ['year', 'condition', 'odometer', 'mmr']\n",
        "interaction_cols = ['age', 'odometer_per_year', 'mmr_odometer_ratio', 'year_condition_interaction']\n",
        "numerical_cols = original_numerical + interaction_cols\n",
        "cluster_features = ['year', 'condition', 'odometer', 'mmr']\n",
        "\n",
        "# === FEATURE ENGINEERING === #\n",
        "def add_interaction_features(df):\n",
        "    df = df.copy()\n",
        "    df[\"age\"] = 2024 - df[\"year\"]\n",
        "    df[\"odometer_per_year\"] = df[\"odometer\"] / (df[\"age\"] + 1e-3)\n",
        "    df[\"mmr_odometer_ratio\"] = df[\"mmr\"] / (df[\"odometer\"] + 1e-3)\n",
        "    df[\"year_condition_interaction\"] = df[\"year\"] * df[\"condition\"]\n",
        "    return df\n",
        "\n",
        "# === PREPROCESSING === #\n",
        "def preprocess_data(df, categorical_cols, numerical_cols, label_encoders=None, scaler=None, fit=True):\n",
        "    df = df.copy()\n",
        "    if fit:\n",
        "        label_encoders = {col: LabelEncoder().fit(df[col].astype(str)) for col in categorical_cols}\n",
        "        scaler = StandardScaler().fit(df[numerical_cols])\n",
        "    for col in categorical_cols:\n",
        "        df[col] = label_encoders[col].transform(df[col].astype(str))\n",
        "    df[numerical_cols] = scaler.transform(df[numerical_cols])\n",
        "    return df, label_encoders, scaler\n",
        "\n",
        "# === LOAD DATA & FEATURE ENGINEERING === #\n",
        "df = pd.read_csv(\"/content/merged_data_2024_column.csv\")\n",
        "df.drop(columns=[\"sellingprice\", \"zipcode\", \"sale_year\"], inplace=True)\n",
        "df = add_interaction_features(df)\n",
        "\n",
        "# === CLUSTERING === #\n",
        "scaler_for_clustering = StandardScaler()\n",
        "scaled_features = scaler_for_clustering.fit_transform(df[cluster_features])\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "df[\"cluster\"] = kmeans.fit_predict(scaled_features)\n",
        "\n",
        "joblib.dump(kmeans, \"kmeans_model.joblib\")\n",
        "joblib.dump(scaler_for_clustering, \"scaler_for_clustering.joblib\")\n",
        "\n",
        "# === TRAINING === #\n",
        "os.makedirs(\"models_by_cluster\", exist_ok=True)\n",
        "\n",
        "for cluster in [0, 1, 2]:\n",
        "    df_cluster = df[df['cluster'] == cluster].copy()\n",
        "    X = df_cluster.drop(columns=['2024_price', 'cluster'])\n",
        "    y = np.log1p(df_cluster['2024_price'])\n",
        "\n",
        "    X_encoded, label_encoders, scaler = preprocess_data(X, categorical_cols, numerical_cols, fit=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    joblib.dump(label_encoders, f\"models_by_cluster/label_encoders_cluster_{cluster}.joblib\", compress=3)\n",
        "    joblib.dump(scaler, f\"models_by_cluster/scaler_cluster_{cluster}.joblib\", compress=3)\n",
        "\n",
        "    if cluster == 1:\n",
        "        print(\"🔍 Tuning LightGBM for Cluster 1...\")\n",
        "        param_grid = {\n",
        "            'num_leaves': [40, 60, 80],\n",
        "            'learning_rate': [0.05, 0.1, 0.2],\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [5, 10, 15]\n",
        "        }\n",
        "\n",
        "        base_model = lgb.LGBMRegressor(random_state=42)\n",
        "        grid = GridSearchCV(base_model, param_grid, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=1)\n",
        "        grid.fit(X_train, y_train)\n",
        "\n",
        "        best_model = grid.best_estimator_\n",
        "        print(f\"✅ Best model for cluster 1: {grid.best_params_}\")\n",
        "    else:\n",
        "        best_model = lgb.LGBMRegressor(num_leaves=50, n_estimators=100, learning_rate=0.5, random_state=42)\n",
        "        best_model.fit(X_train, y_train)\n",
        "\n",
        "    joblib.dump({'model': best_model}, f\"models_by_cluster/lightgbm_model_cluster_{cluster}.joblib\", compress=3)\n",
        "\n",
        "# === PREDICTION FUNCTION === #\n",
        "def predict_cluster_and_price(car_input: pd.DataFrame):\n",
        "    cluster_input = car_input[cluster_features].copy()\n",
        "    cluster_scaled = scaler_for_clustering.transform(cluster_input)\n",
        "    cluster = kmeans.predict(cluster_scaled)[0]\n",
        "\n",
        "    label_encoders = joblib.load(f\"models_by_cluster/label_encoders_cluster_{cluster}.joblib\")\n",
        "    scaler = joblib.load(f\"models_by_cluster/scaler_cluster_{cluster}.joblib\")\n",
        "\n",
        "    car = add_interaction_features(car_input.copy())\n",
        "    for col in categorical_cols:\n",
        "        car[col] = label_encoders[col].transform(car[col].astype(str))\n",
        "    X_cat = car[categorical_cols].values\n",
        "    X_num = scaler.transform(car[numerical_cols])\n",
        "    X_input = np.hstack((X_cat, X_num)).astype(np.float32)\n",
        "\n",
        "    model = joblib.load(f\"models_by_cluster/lightgbm_model_cluster_{cluster}.joblib\")['model']\n",
        "    y_log_pred = model.predict(X_input)\n",
        "    y_pred = np.expm1(y_log_pred)\n",
        "    return cluster, y_pred[0]\n",
        "\n",
        "# === EVALUATION === #\n",
        "print(\"\\n=== Final Evaluation per Cluster (With Feature Engineering + Tuning) ===\")\n",
        "for cluster in [0, 1, 2]:\n",
        "    df_cluster = df[df['cluster'] == cluster].copy()\n",
        "    X = df_cluster.drop(columns=['2024_price', 'cluster'])\n",
        "    y_true = df_cluster['2024_price'].values\n",
        "\n",
        "    X = add_interaction_features(X)\n",
        "    label_encoders = joblib.load(f\"models_by_cluster/label_encoders_cluster_{cluster}.joblib\")\n",
        "    scaler = joblib.load(f\"models_by_cluster/scaler_cluster_{cluster}.joblib\")\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        X[col] = label_encoders[col].transform(X[col].astype(str))\n",
        "    X[numerical_cols] = scaler.transform(X[numerical_cols])\n",
        "    X_input = X.values.astype(np.float32)\n",
        "\n",
        "    model = joblib.load(f\"models_by_cluster/lightgbm_model_cluster_{cluster}.joblib\")['model']\n",
        "    y_log_pred = model.predict(X_input)\n",
        "    y_pred = np.expm1(y_log_pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"Cluster {cluster} - RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIR0M8rqsAvr",
        "outputId": "c5a7a843-d2d2-4dff-b7e9-76f555de1cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a73fb6944a1e>:39: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/merged_data_2024_column.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059814 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1883\n",
            "[LightGBM] [Info] Number of data points in the train set: 109297, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 10.370771\n",
            "🔍 Tuning LightGBM for Cluster 1...\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066176 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2267\n",
            "[LightGBM] [Info] Number of data points in the train set: 368864, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 9.128428\n",
            "✅ Best model for cluster 1: {'learning_rate': 0.2, 'max_depth': 15, 'n_estimators': 200, 'num_leaves': 80}\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010000 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1951\n",
            "[LightGBM] [Info] Number of data points in the train set: 56952, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 9.256129\n",
            "\n",
            "=== Final Evaluation per Cluster (With Feature Engineering + Tuning) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0 - RMSE: 2503.47, R²: 0.9612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 1 - RMSE: 5595.76, R²: 0.7072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 2 - RMSE: 2124.32, R²: 0.9717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "car = pd.DataFrame([{\n",
        "    'year': 2024,\n",
        "    'make': 'Kia',\n",
        "    'model': 'Sorento',\n",
        "    'trim': 'LX',\n",
        "    'state': 'ca',\n",
        "    'condition': 5,\n",
        "    'odometer': 0,\n",
        "    'color': 'white',\n",
        "    'interior': 'black',\n",
        "    'mmr': 20500\n",
        "}])\n",
        "\n",
        "cluster_id, predicted_price = predict_cluster_and_price(car)\n",
        "print(f\"Cluster: {cluster_id}, Predicted 2024 Price: ${predicted_price:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QdeK3oI0Bj5",
        "outputId": "20495b32-d09f-4efb-8623-7ea6878ee7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster: 2, Predicted 2024 Price: $13212.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'year': [2015, 2015, 2014, 2015, 2014],\n",
        "    'make': ['Kia', 'Kia', 'BMW', 'Volvo', 'BMW'],\n",
        "    'model': ['Sorento', 'Sorento', '3 Series', 'S60', '6 Series Gran Coupe'],\n",
        "    'trim': ['LX', 'LX', '328i SULEV', 'T5', '650i'],\n",
        "    'state': ['CA', 'CA', 'CA', 'CA', 'CA'],\n",
        "    'condition': [5.0, 5.0, 4.5, 4.1, 4.3],\n",
        "    'odometer': [16639.0, 9393.0, 1331.0, 14282.0, 2641.0],\n",
        "    'color': ['white', 'white', 'gray', 'white', 'gray'],\n",
        "    'interior': ['black', 'beige', 'black', 'black', 'black'],\n",
        "    'mmr': [20500.0, 20800.0, 31900.0, 27500.0, 66000.0],\n",
        "    '2024_price': [28666.67, 28666.67, 39949.37, 36953.16, 89333.33],\n",
        "    'cluster': [2, 2, 0, 0, 0]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "7HGgQY5tRECo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://autohaggleapi.onrender.com/predict\"\n",
        "\n",
        "test_data = {\n",
        "    \"year\": 2015,\n",
        "    \"make\": \"Kia\",\n",
        "    \"model\": \"Sorento\",\n",
        "    \"trim\": \"LX\",\n",
        "    \"state\": \"ca\",\n",
        "    \"condition\": 5,\n",
        "    \"odometer\": 0,\n",
        "    \"color\": \"white\",\n",
        "    \"interior\": \"black\",\n",
        "    \"mmr\": 20500\n",
        "}\n",
        "\n",
        "response = requests.post(API_URL, json=test_data)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Success! Prediction received:\")\n",
        "    print(response.json())\n",
        "else:\n",
        "    print(\"Error:\", response.status_code, response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hutUmFIwgMj1",
        "outputId": "64d8bfd6-7c99-4851-824c-47693d2d4f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Prediction received:\n",
            "{'cluster': 2, 'predicted_price': 12538.93}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/models_by_cluster.zip /content/models_by_cluster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO5brapSaZDn",
        "outputId": "2bae95d5-e55c-4550-de7a-b8b888941f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/models_by_cluster/ (stored 0%)\n",
            "  adding: content/models_by_cluster/lightgbm_model_cluster_1.joblib (deflated 0%)\n",
            "  adding: content/models_by_cluster/scaler_cluster_1.joblib (stored 0%)\n",
            "  adding: content/models_by_cluster/lightgbm_model_cluster_0.joblib (deflated 0%)\n",
            "  adding: content/models_by_cluster/label_encoders_cluster_2.joblib (stored 0%)\n",
            "  adding: content/models_by_cluster/lightgbm_model_cluster_2.joblib (deflated 0%)\n",
            "  adding: content/models_by_cluster/label_encoders_cluster_1.joblib (deflated 0%)\n",
            "  adding: content/models_by_cluster/scaler_cluster_2.joblib (stored 0%)\n",
            "  adding: content/models_by_cluster/label_encoders_cluster_0.joblib (stored 0%)\n",
            "  adding: content/models_by_cluster/scaler_cluster_0.joblib (stored 0%)\n"
          ]
        }
      ]
    }
  ]
}